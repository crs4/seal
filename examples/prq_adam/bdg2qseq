#!/usr/bin/env python

import seal

import getpass
import os
import sys
import pydoop.hdfs as phdfs
from pydoop.app.main import main as pydoop_main

ExampleDir = os.path.abspath(os.path.dirname(__file__))

INPUT_FORMAT = 'org.apache.parquet.avro.AvroParquetInputFormat'
OUTPUT_FORMAT = 'it.crs4.pydoop.NoSeparatorTextOutputFormat'

MODULE = 'bdg2qseq'
MPY = '%s.py' % MODULE

LOGLEVEL = 'DEBUG'

def stage_data(in_path, out_path):
    phdfs.mkdir('/user/%s' % getpass.getuser())
    if phdfs.path.exists(in_path):
        print >> sys.stderr, "Input path %s already exists on HDFS" % in_path
    else:
        phdfs.put(in_path, in_path)
    try:
        print >> sys.stderr, "removing output path %s (if it exists)" % out_path
        phdfs.rmr(out_path)
    except IOError:
        pass

def main():
    if len(sys.argv) != 3:
        print >> sys.stderr, "USAGE:  %s PARQUET_IN_PATH QSEQ_OUT_PATH" % os.path.basename(__file__)
        sys.exit(1)

    input_path, output_path = sys.argv[1:]
    stage_data(input_path, output_path)

    submit_args = [
        'submit',
        '--upload-file-to-cache', MPY,
        '--num-reducers', '0',
        '--input-format', INPUT_FORMAT,
        '--output-format', OUTPUT_FORMAT,
        '--avro-input', 'v',
        '--log-level', LOGLEVEL,
        '--job-name', MODULE ]
    submit_args.extend(seal.libjars())

    submit_args.extend((
        MODULE, input_path, output_path
        ))
    print >> sys.stderr, "pydoop args:", submit_args
    pydoop_main(submit_args)

if __name__ == '__main__':
    main()
