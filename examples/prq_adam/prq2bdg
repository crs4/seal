#!/usr/bin/env python

import seal

import getpass
import os
import sys
import pydoop.hdfs as phdfs
from pydoop.app.main import main as pydoop_main

ExampleDir = os.path.abspath(os.path.dirname(__file__))

OUT_SCHEMA_FILE_LOCAL = os.path.join(ExampleDir, 'Fragment.avsc')

MODULE = 'prq2bdg'
MPY = '%s.py' % MODULE

LOGLEVEL = 'DEBUG'

def stage_data(in_path, out_path):
    phdfs.mkdir('/user/%s' % getpass.getuser())
    if phdfs.path.exists(in_path):
        print >> sys.stderr, "Input path %s already exists on HDFS" % in_path
    else:
        phdfs.put(in_path, in_path)
    try:
        print >> sys.stderr, "removing output path %s (if it exists)" % out_path
        phdfs.rmr(out_path)
    except IOError:
        pass

def main():
    if len(sys.argv) != 3:
        print >> sys.stderr, "USAGE:  %s PRQ_IN_PATH PARQUET_OUT_PATH" % os.path.basename(__file__)
        sys.exit(1)

    input_path, output_path = sys.argv[1:]
    with open(OUT_SCHEMA_FILE_LOCAL) as f:
        out_schema = f.read()

    stage_data(input_path, output_path)

    submit_args = [
        'submit',
        '--upload-file-to-cache', MPY,
        '-D', 'pydoop.mapreduce.avro.value.output.schema=%s' % out_schema,
        '-D', 'parquet.avro.schema=%s' % out_schema,
        '--num-reducers', '0',
        '--output-format', 'org.apache.parquet.avro.AvroParquetOutputFormat',
        '--avro-output', 'v',
        '--log-level', LOGLEVEL,
        '--job-name', MODULE ]
    submit_args.extend(seal.libjars())
    submit_args.extend((
        MODULE, input_path, output_path
        ))
    submit_args.extend(seal.libjars())
    pydoop_main(submit_args)

if __name__ == '__main__':
    main()
